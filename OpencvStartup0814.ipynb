{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bigred/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import better_exceptions\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from keras.utils import Sequence, to_categorical\n",
    "import Augmentor\n",
    "\n",
    "\n",
    "def get_transform_func():\n",
    "    p = Augmentor.Pipeline()\n",
    "    p.flip_left_right(probability=0.5)\n",
    "    p.rotate(probability=1, max_left_rotation=5, max_right_rotation=5)\n",
    "    p.zoom_random(probability=0.5, percentage_area=0.95)\n",
    "    p.random_distortion(probability=0.5, grid_width=2, grid_height=2, magnitude=8)\n",
    "    p.random_color(probability=1, min_factor=0.8, max_factor=1.2)\n",
    "    p.random_contrast(probability=1, min_factor=0.8, max_factor=1.2)\n",
    "    p.random_brightness(probability=1, min_factor=0.8, max_factor=1.2)\n",
    "    p.random_erasing(probability=0.5, rectangle_area=0.2)\n",
    "\n",
    "    def transform_image(image):\n",
    "        image = [Image.fromarray(image)]\n",
    "        for operation in p.operations:\n",
    "            r = round(random.uniform(0, 1), 1)\n",
    "            if r <= operation.probability:\n",
    "                image = operation.perform_operation(image)\n",
    "        return image[0]\n",
    "    return transform_image\n",
    "\n",
    "\n",
    "class FaceGenerator(Sequence):\n",
    "    def __init__(self, appa_dir, utk_dir=None, batch_size=32, image_size=224):\n",
    "        self.image_path_and_age = []\n",
    "        self._load_appa(appa_dir)\n",
    "\n",
    "        if utk_dir:\n",
    "            self._load_utk(utk_dir)\n",
    "\n",
    "        self.image_num = len(self.image_path_and_age)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.indices = np.random.permutation(self.image_num)\n",
    "        self.transform_image = get_transform_func()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_num // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_size = self.batch_size\n",
    "        image_size = self.image_size\n",
    "        x = np.zeros((batch_size, image_size, image_size, 3), dtype=np.uint8)\n",
    "        y = np.zeros((batch_size, 1), dtype=np.int32)\n",
    "\n",
    "        sample_indices = self.indices[idx * batch_size:(idx + 1) * batch_size]\n",
    "\n",
    "        for i, sample_id in enumerate(sample_indices):\n",
    "            image_path, age = self.image_path_and_age[sample_id]\n",
    "            image = cv2.imread(str(image_path))\n",
    "            x[i] = self.transform_image(cv2.resize(image, (image_size, image_size)))\n",
    "            age += math.floor(np.random.randn() * 2 + 0.5)\n",
    "            y[i] = np.clip(age, 0, 100)\n",
    "\n",
    "        return x, to_categorical(y, 101)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.random.permutation(self.image_num)\n",
    "\n",
    "    def _load_appa(self, appa_dir):\n",
    "        appa_root = Path(appa_dir)\n",
    "        train_image_dir = appa_root.joinpath(\"train\")\n",
    "        gt_train_path = appa_root.joinpath(\"gt_avg_train.csv\")\n",
    "        df = pd.read_csv(str(gt_train_path))\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            age = min(100, int(row.apparent_age_avg))\n",
    "            # age = int(row.real_age)\n",
    "            image_path = train_image_dir.joinpath(row.file_name + \"_face.jpg\")\n",
    "\n",
    "            if image_path.is_file():\n",
    "                self.image_path_and_age.append([str(image_path), age])\n",
    "\n",
    "    def _load_utk(self, utk_dir):\n",
    "        image_dir = Path(utk_dir)\n",
    "\n",
    "        for image_path in image_dir.glob(\"*.jpg\"):\n",
    "            image_name = image_path.name  # [age]_[gender]_[race]_[date&time].jpg\n",
    "            age = min(100, int(image_name.split(\"_\")[0]))\n",
    "\n",
    "            if image_path.is_file():\n",
    "                self.image_path_and_age.append([str(image_path), age])\n",
    "\n",
    "\n",
    "class ValGenerator(Sequence):\n",
    "    def __init__(self, appa_dir, batch_size=32, image_size=224):\n",
    "        self.image_path_and_age = []\n",
    "        self._load_appa(appa_dir)\n",
    "        self.image_num = len(self.image_path_and_age)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_num // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_size = self.batch_size\n",
    "        image_size = self.image_size\n",
    "        x = np.zeros((batch_size, image_size, image_size, 3), dtype=np.uint8)\n",
    "        y = np.zeros((batch_size, 1), dtype=np.int32)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            image_path, age = self.image_path_and_age[idx * batch_size + i]\n",
    "            image = cv2.imread(str(image_path))\n",
    "            x[i] = cv2.resize(image, (image_size, image_size))\n",
    "            y[i] = age\n",
    "\n",
    "        return x, to_categorical(y, 101)\n",
    "\n",
    "    def _load_appa(self, appa_dir):\n",
    "        appa_root = Path(appa_dir)\n",
    "        val_image_dir = appa_root.joinpath(\"valid\")\n",
    "        gt_val_path = appa_root.joinpath(\"gt_avg_valid.csv\")\n",
    "        df = pd.read_csv(str(gt_val_path))\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            age = min(100, int(row.apparent_age_avg))\n",
    "            # age = int(row.real_age)\n",
    "            image_path = val_image_dir.joinpath(row.file_name + \"_face.jpg\")\n",
    "\n",
    "            if image_path.is_file():\n",
    "                self.image_path_and_age.append([str(image_path), age])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2\n",
    "   * 套件與模組導入\n",
    "   * 功能實現\n",
    "   * 結束並釋放資源\n",
    "   * [OPENCV基礎2](https://zhuanlan.zhihu.com/p/32904337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 導入模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取圖片檔 (檔名,引數)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 圖像矩陣輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34  34  34 ... 154 154 155]\n",
      " [ 34  34  34 ... 154 154 155]\n",
      " [ 34  34  34 ... 153 153 154]\n",
      " ...\n",
      " [ 40  40  40 ...  47  47  53]\n",
      " [ 44  44  44 ...  47  47  47]\n",
      " [ 46  46  46 ...  47  47  46]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img=cv.imread(\"123.jpeg\",2) ###flag=-1時，8位深度，原通道 flag=0，8位深度，1通道 flag=1, 8位深度 ，3通道 flag=2，原深度，1通道 flag=3, 原深度，3通道 flag=4，8位深度 ，3通道###\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 圖像輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 321)\n",
      "uint8\n",
      "0\n",
      "255\n",
      "[[34]\n",
      " [34]\n",
      " [34]\n",
      " ...\n",
      " [47]\n",
      " [47]\n",
      " [46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(img.shape)\n",
    "print(img.dtype)\n",
    "print(img.min())\n",
    "print(img.max())\n",
    "img_reshape=img.reshape(-1,1)\n",
    "print(img_reshape)\n",
    "\n",
    "#建立視窗並顯示影象\n",
    "cv.namedWindow(\"img\")\n",
    "cv.imshow(\"img\",img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#釋放視窗\n",
    "cv.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 劃線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.line(img,(0,0),(511,511),(255,0,0),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.namedWindow(\"img\")\n",
    "cv.imshow(\"img\",img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#釋放視窗\n",
    "cv.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 輔助線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=cv.rectangle(img,pt1,pt2,color,lineType)\n",
    "img=cv.rectangle(img,(384,0),(510,128),(0,255,0),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.namedWindow(\"img\")\n",
    "cv.imshow(\"img\",img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#釋放視窗\n",
    "cv.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畫圓圈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.circle(img,(447,63),63,(0,0,255),-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取Louisa影片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[影像轉圖片](https://blog.csdn.net/m0_37733057/article/details/79023693)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vc = cv2.VideoCapture('20190410.avi') #读入视频文件\n",
    "c=0\n",
    "rval=vc.isOpened()\n",
    "#timeF = 1  #视频帧计数间隔频率\n",
    "while rval:   #循环读取视频帧\n",
    "    c = c + 1\n",
    "    rval, frame = vc.read()\n",
    "#    if(c%timeF == 0): #每隔timeF帧进行存储操作\n",
    "#        cv2.imwrite('smallVideo/smallVideo'+str(c) + '.jpg', frame) #存储为图像\n",
    "    if rval:\n",
    "        cv2.imwrite('20190410/20190410'+str(c).zfill(8) + '.jpg', frame) #存储为图像\n",
    "        cv2.waitKey(1)\n",
    "    else:\n",
    "        break\n",
    "vc.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测出图片中的人脸，并用方框标记出来\n",
    "    def face_detector(image, cascade):\n",
    "        global face_num #引用全局变量\n",
    "        grayImage = cv.cvtColor(image, cv.COLOR_BGR2GRAY) #灰度化图片 \n",
    "        equalImage = cv.equalizeHist(grayImage) #直方图均衡化\n",
    "        faces = cascade.detectMultiScale(equalImage, scaleFactor=1.3, minNeighbors=3)\n",
    "     \n",
    "        for (x,y,w,h) in faces:\n",
    "            #裁剪出人脸，单独保存成图片，注意这里的横坐标与纵坐标不知为啥颠倒了\n",
    "            #cv.imwrite(\"face_%s.png\" %(face_num), image[y:y+h,x:x+w])\n",
    "            cv.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            face_num = face_num + 1\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
